{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2110d700-ac39-4ec7-8446-d860d4317b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, make_scorer, recall_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4205e2a3-7bd5-41d8-b814-12aae2e5c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing CSV files\n",
    "train_df = pd.read_csv('train_data.csv')\n",
    "test_df = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "576d387c-0d28-4760-94e0-b43467589e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels for the training set\n",
    "X_train = train_df.drop('Air Quality', axis=1)\n",
    "y_train = train_df['Air Quality']\n",
    "\n",
    "# Separate features and labels for the testing set\n",
    "X_test = test_df.drop('Air Quality', axis=1)\n",
    "y_test = test_df['Air Quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41f2f027-7a2d-40a4-82e8-2c75c956f076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (3000, 9)\n",
      "Training labels shape: (3000,)\n",
      "Testing features shape: (1000, 9)\n",
      "Testing labels shape: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Display the shapes to verify\n",
    "print(\"Training features shape:\", X_train.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Testing features shape:\", X_test.shape)\n",
    "print(\"Testing labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2866adcc-5254-4e0c-b18b-e2c649be835a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "Best Decision Tree Parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Weighted Mean Training Score: 0.9856666666666667\n",
      "Weighted Mean Cross-Validation Score: 0.9333333333333333\n",
      "Decision Tree - Training Data:\n",
      "[[1200    0    0    0]\n",
      " [   0  289    0   11]\n",
      " [   0    0  882   18]\n",
      " [   0    7   10  583]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       1.00      1.00      1.00      1200\n",
      "   Hazardous       0.98      0.96      0.97       300\n",
      "    Moderate       0.99      0.98      0.98       900\n",
      "        Poor       0.95      0.97      0.96       600\n",
      "\n",
      "    accuracy                           0.98      3000\n",
      "   macro avg       0.98      0.98      0.98      3000\n",
      "weighted avg       0.98      0.98      0.98      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Decision Tree Model Training and Evaluation\n",
    "# Define hyperparameter grid for Decision Tree\n",
    "dt_param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Define StratifiedKFold for cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define metric for scoring (weighted recall)\n",
    "weighted_recall = make_scorer(recall_score, average='weighted')\n",
    "\n",
    "# Define GridSearchCV object\n",
    "dt_grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid=dt_param_grid,\n",
    "    scoring=weighted_recall,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Run the grid search\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "# Display best model parameters and score\n",
    "print(\"Best Decision Tree Parameters:\", dt_grid.best_params_)\n",
    "print(\"Weighted Mean Training Score:\", dt_grid.cv_results_['mean_train_score'][dt_grid.best_index_])\n",
    "print(\"Weighted Mean Cross-Validation Score:\", dt_grid.best_score_)\n",
    "\n",
    "# Evaluate on training data\n",
    "dt_train_preds = dt_grid.predict(X_train)\n",
    "print(\"Decision Tree - Training Data:\")\n",
    "print(confusion_matrix(y_train, dt_train_preds))\n",
    "print(classification_report(y_train, dt_train_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69accb50-2a9b-4f0b-a150-799aad48bfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Best SVM Parameters: {'svc__C': 1, 'svc__degree': 2, 'svc__gamma': 'scale', 'svc__kernel': 'rbf'}\n",
      "Weighted Mean Training Score: 0.9616666666666667\n",
      "Weighted Mean Cross-Validation Score: 0.9443333333333334\n",
      "SVM - Training Data:\n",
      "[[1199    0    1    0]\n",
      " [   0  276    0   24]\n",
      " [   2    0  875   23]\n",
      " [   0   36   30  534]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       1.00      1.00      1.00      1200\n",
      "   Hazardous       0.88      0.92      0.90       300\n",
      "    Moderate       0.97      0.97      0.97       900\n",
      "        Poor       0.92      0.89      0.90       600\n",
      "\n",
      "    accuracy                           0.96      3000\n",
      "   macro avg       0.94      0.95      0.94      3000\n",
      "weighted avg       0.96      0.96      0.96      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. SVM Model Training and Evaluation\n",
    "# Define pipeline for SVM (scaling + SVC)\n",
    "svm_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(class_weight='balanced', random_state=42))\n",
    "])\n",
    "\n",
    "# Define hyperparameter grid for SVM\n",
    "svm_param_grid = {\n",
    "    'svc__C': [0.1, 1, 10, 100],\n",
    "    'svc__kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'svc__gamma': ['scale', 'auto', 0.1, 1],\n",
    "    'svc__degree': [2, 3]  # Only relevant for polynomial kernel\n",
    "}\n",
    "\n",
    "# Define GridSearchCV object for SVM\n",
    "svm_grid = GridSearchCV(\n",
    "    svm_pipeline,\n",
    "    param_grid=svm_param_grid,\n",
    "    scoring=weighted_recall,\n",
    "    cv=cv,\n",
    "    n_jobs=-1,  # Use all available cores\n",
    "    verbose=1,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "# Run the grid search\n",
    "svm_grid.fit(X_train, y_train)\n",
    "\n",
    "# Display best model parameters and score\n",
    "print(\"Best SVM Parameters:\", svm_grid.best_params_)\n",
    "print(\"Weighted Mean Training Score:\", svm_grid.cv_results_['mean_train_score'][svm_grid.best_index_])\n",
    "print(\"Weighted Mean Cross-Validation Score:\", svm_grid.best_score_)\n",
    "\n",
    "# Evaluate on training data\n",
    "svm_train_preds = svm_grid.predict(X_train)\n",
    "print(\"SVM - Training Data:\")\n",
    "print(confusion_matrix(y_train, svm_train_preds))\n",
    "print(classification_report(y_train, svm_train_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2beff7-903b-4835-a2de-2891feebfdf2",
   "metadata": {},
   "source": [
    "### Performance Summary\n",
    "\n",
    "#### Decision Tree\n",
    "\n",
    "Best Parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
    "\n",
    "Weighted Mean Training Score: 0.9857\n",
    "\n",
    "Weighted Mean Cross-Validation Score: 0.9333\n",
    "\n",
    "Training Accuracy: 0.98\n",
    "\n",
    "#### SVM\n",
    "\n",
    "Best Parameters: {'svc__C': 1, 'svc__degree': 2, 'svc__gamma': 'scale', 'svc__kernel': 'rbf'}\n",
    "\n",
    "Weighted Mean Training Score: 0.9617\n",
    "\n",
    "Weighted Mean Cross-Validation Score: 0.9443\n",
    "\n",
    "Training Accuracy: 0.96\n",
    "\n",
    "### Overfitting/Underfitting\n",
    "\n",
    "Decision Tree: The decision tree has a high training score (0.9857) but a lower cross-validation score (0.9333). This suggests overfitting, meaning the model has memorized the training data and might not generalize well to new, unseen data.\n",
    "\n",
    "SVM: The SVM has a lower training score (0.9617) but a higher cross-validation score (0.9443) compared to the decision tree. The training score is closer to the cross-validation score, suggesting less overfitting. The SVM generalizes better than the decision tree.\n",
    "\n",
    "### Important Metrics\n",
    "\n",
    "Based on the Project Use Case, the most important metric is recall, especially for the \"Hazardous\" and \"Poor\" air quality classes. The goal of this project is to minimize false negatives. The confusion matrices and classification reports show details of the models.\n",
    "\n",
    "Decision Tree:\n",
    "\n",
    "\"Hazardous\" recall: 0.96 (289/300)\n",
    "\n",
    "\"Poor\" recall: 0.97 (583/600)\n",
    "\n",
    "SVM:\n",
    "\n",
    "\"Hazardous\" recall: 0.92 (276/300)\n",
    "\n",
    "\"Poor\" recall: 0.89 (534/600)\n",
    "\n",
    "The Decision Tree has a higher recall for both \"Hazardous\" and \"Poor\" classes.\n",
    "\n",
    "### Additional Observations\n",
    "\n",
    "The confusion matrix for the decision tree shows perfect classification for the \"Good\" class, but has more misclassifications in the \"Hazardous\", \"Moderate\", and \"Poor\" classes.\n",
    "\n",
    "The SVM's confusion matrix also shows good performance in the \"Good\" class, but compared to the decision tree, it misclassifies more instances in the \"Hazardous\" and \"Poor\" categories.\n",
    "\n",
    "## Choosing the Best Model\n",
    "\n",
    "Considering all factors, the Decision Tree is the better model due to a higher recall score in the \"Hazardous\" class. Therefore, it is more desirable for this particular use case to focus on capturing all instances where the air quality is \"Hazardous.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22fc205a-f5dc-4641-ac2e-587a3746955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model (selected based on recall for 'Hazardous' class): Decision Tree\n",
      "Saved best model to best_air_quality_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# 4. Model Comparison and Selection (manual selection based on recall for 'Hazardous' class)\n",
    "# Based on analysis, the Decision Tree is preferred for its higher recall on critical classes\n",
    "\n",
    "best_model = dt_grid.best_estimator_\n",
    "best_model_name = \"Decision Tree\"\n",
    "\n",
    "print(f\"Best Model (selected based on recall for 'Hazardous' class): {best_model_name}\")\n",
    "\n",
    "# Save the best model to a file\n",
    "filename = 'best_air_quality_model.pkl'\n",
    "pickle.dump(best_model, open(filename, 'wb'))\n",
    "print(f\"Saved best model to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d5226db-4621-48bc-a8c9-5620749571bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Metrics:\n",
      "[[399   0   1   0]\n",
      " [  0  74   0  26]\n",
      " [  4   0 285  11]\n",
      " [  0  19  15 166]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Good       0.99      1.00      0.99       400\n",
      "   Hazardous       0.80      0.74      0.77       100\n",
      "    Moderate       0.95      0.95      0.95       300\n",
      "        Poor       0.82      0.83      0.82       200\n",
      "\n",
      "    accuracy                           0.92      1000\n",
      "   macro avg       0.89      0.88      0.88      1000\n",
      "weighted avg       0.92      0.92      0.92      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Final Model Evaluation on Test Data\n",
    "# Load the model from the pickle file\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_preds = loaded_model.predict(X_test)\n",
    "\n",
    "# Display evaluation metrics\n",
    "print(\"Test Data Metrics:\")\n",
    "print(confusion_matrix(y_test, test_preds))\n",
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9a29c6-867d-4be8-8e27-3ad756408b81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
